{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week10_naive_bayes_completed",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "0IdAoixSAPZU",
        "zVrBlx4AAPZj",
        "pIliDqauAPZq",
        "lrNHcKoCAPZr",
        "xmHQV98BAPZ8",
        "oot7oveOAPaA",
        "tHRQlRreAPaE",
        "366PeEg2APaJ",
        "SJkYTHF9APaL"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "_JlwZIH6APXB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![ADSA Logo](http://i.imgur.com/BV0CdHZ.png?2 \"ADSA Logo\")"
      ]
    },
    {
      "metadata": {
        "id": "pEdyF3z4APXC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fall 2018 ADSA Workshop - Naive Bayes from Scratch\n",
        "\n",
        "Workshop content is adapted from:\n",
        "* https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/\n"
      ]
    },
    {
      "metadata": {
        "id": "HS6BojxV8oug",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Naive Bayes algorithm is an intuitive method that uses the probabilities of each attribute belonging to each class to make a prediction. It is the supervised learning approach you would come up with if you wanted to model a predictive modeling problem probabilistically.\n",
        "\n",
        "Naive bayes simplifies the calculation of probabilities by assuming that the probability of each attribute belonging to a given class value is independent of all other attributes. This is a strong assumption but results in a fast and effective method.\n",
        "\n",
        "The probability of a class value given a value of an attribute is called the conditional probability. By multiplying the conditional probabilities together for each attribute for a given class value, we have a probability of a data instance belonging to that class.\n",
        "\n",
        "To make a prediction we can calculate probabilities of the instance belonging to each class and select the class value with the highest probability.\n",
        "\n",
        "Naive bases is often described using categorical data because it is easy to describe and calculate using ratios. A more useful version of the algorithm for our purposes supports numeric attributes and assumes the values of each numerical attribute are normally distributed (fall somewhere on a bell curve). Again, this is a strong assumption, but still gives robust results."
      ]
    },
    {
      "metadata": {
        "id": "cxwo6Xg39oei",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Pima Indians Diabetes Problem\n",
        "This dataset contain 768 observations of medical details for Pima Indian patients. The records describe instantaneous measurements taken from the patient such as their age, the number of times pregnant and blood workup. All patients are women aged 21 or older. All attributes are numeric, and their units vary from attribute to attribute.\n",
        "\n",
        "Each record has a class value that indicates whether the patient suffered an onset of diabetes within 5 years of when the measurements were taken (1) or not (0).\n",
        "\n",
        "This is a standard dataset that has been studied a lot in machine learning literature. A good prediction accuracy is 70%-76%."
      ]
    },
    {
      "metadata": {
        "id": "hFqLJOKA-H7_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Reading in the dataset"
      ]
    },
    {
      "metadata": {
        "id": "J8TYU_gy9xQ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import io\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "df = pd.read_csv(io.StringIO(uploaded['pima_indians_diabetes.csv'].decode('utf-8')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "__zRgMAn--kc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Note that the csv data is now a Pandas DataFrame\n",
        "print(type(df))\n",
        "\n",
        "# Returns first 5 entries\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-fq955w3_fM8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Naive Bayes Algorithm\n",
        "###1. Split Data: split the data into training and testing datasets.\n",
        "###2. Summarize Data: summarize the properties in the training dataset so that we can calculate probabilities and make predictions.\n",
        "###3. Make Predictions: Generate predictions given a test dataset and a summarized training dataset.\n",
        "###4. Evaluate Accuracy: Evaluate the accuracy of predictions made for a test dataset as the percentage correct out of all predictions made.\n",
        "###5. Tie it Together: Use all of the code elements to present a complete and standalone implementation of the Naive Bayes algorithm."
      ]
    },
    {
      "metadata": {
        "id": "qThPYBcOCdJN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##1. Split data\n",
        "Use the train_test_split function to create the training and testing data. "
      ]
    },
    {
      "metadata": {
        "id": "AyCbigtZ_jka",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CRXTV5BcBPq7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features = df[['x1','x2','x3','x4','x5','x6','x7','x8']]\n",
        "labels    = df[['y1']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1erBnGClBTSb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t_zGAq6jBYdo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m6xTcR-g_vxL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size = .2,random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yfNc31IpBhjp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(len(x_train))\n",
        "x_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8RaR_M7QBj-X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(len(y_train))\n",
        "y_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kPFnsYIVB197",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(len(x_test))\n",
        "x_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S2fasosJB6dC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(len(y_test))\n",
        "y_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WJyYbq6JCjVD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##2. Summarize Data\n",
        "This step can be broken down into a series of steps. \n",
        "\n",
        "a. Separate Data By Class\n",
        "\n",
        "b. Calculate Mean\n",
        "\n",
        "c. Calculate Standard Deviation\n"
      ]
    },
    {
      "metadata": {
        "id": "PnaUYtKzDZbk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Separate Data by Class"
      ]
    },
    {
      "metadata": {
        "id": "pYvxl-4MClyR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for all of the y_train data, extract only 1 values\n",
        "one_y  = y_train[y_train.y1 == 1] \n",
        "# use the indices of one_y to get the corresponding rows in x_train\n",
        "one_x  = x_train.loc[list(one_y.index)]\n",
        "\n",
        "zero_y = y_train[y_train.y1 == 0]\n",
        "zero_x = x_train.loc[list(zero_y.index)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KAJ-jiv9IKvD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Calulate Mean"
      ]
    },
    {
      "metadata": {
        "id": "Z7ZazL0LINz8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "one_mean  = one_x.mean()\n",
        "print(one_mean)\n",
        "zero_mean = zero_x.mean() \n",
        "print(zero_mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kJQgka3IjTD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Calculate Standard Deviation"
      ]
    },
    {
      "metadata": {
        "id": "Fw06asH6ImY4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "one_sd  = one_x.std()\n",
        "print(one_sd)\n",
        "zero_sd = zero_x.std()\n",
        "print(zero_sd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1P4vsm4PMXLM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Make Predictions\n",
        "We are now ready to make predictions using the summaries prepared from our training data. Making predictions involves calculating the probability that a given data instance belongs to each class, then selecting the class with the largest probability as the prediction.\n",
        "\n",
        "We can also divide this part into a series of steps: \n",
        "\n",
        "a. Calculate Gaussian Probability Density Function\n",
        "\n",
        "b. Calculate Class Probabilities\n",
        "\n",
        "c. Make Predictions\n",
        "\n",
        "d. Estimate Accuracy"
      ]
    },
    {
      "metadata": {
        "id": "jgKCbhMIMvUI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "# this function the is the pdf formula for normal distributions that can be found here http://scikit-learn.org/stable/modules/naive_bayes.html\n",
        "def calculateProbability(x, mean, stdev):\n",
        "\texponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
        "\treturn (1 / (math.sqrt(2*math.pi) * stdev)) * exponent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FhkDcwvWP2-4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_calc = []\n",
        "# iterate through the the x_test dataframe row by row\n",
        "for i in range(0,len(x_test)):\n",
        "  calc_one = []\n",
        "  \n",
        "  # calculate the probabilities using the means and sds of the 1 labels\n",
        "  for j in range(0,len(one_sd)):\n",
        "    calc_one.append(calculateProbability(x_test.iloc[i][j],one_mean[j],one_sd[j]))\n",
        "  calc_zero = []\n",
        "  \n",
        "  # calculate the probabilities using the means and sds of the 0 labels\n",
        "  for j in range(0,len(zero_sd)):\n",
        "    calc_zero.append(calculateProbability(x_test.iloc[i][j],zero_mean[j],zero_sd[j]))\n",
        "    \n",
        "  # append both lists of probabilities into a final list\n",
        "  all_calc.append([calc_one,calc_zero])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mpqtddbrTbhm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "# iterate through our list containing lists of two lists of probabilities \n",
        "for calc in all_calc: \n",
        "  zero = 0\n",
        "  one  = 0\n",
        "  # now iterate through our two lists of probabilities\n",
        "  for i in range(0,len(calc[0])): \n",
        "    \n",
        "    # check which one has a greater probabilty\n",
        "    if calc[0][i] > calc[1][i]: \n",
        "      one += 1\n",
        "    else: \n",
        "      zero += 1\n",
        "      \n",
        "  # if our one count was greater than a zero count, then the data point corresponding to this index is 1(has diabetes)\n",
        "  if one > zero: \n",
        "    predictions.append(1)\n",
        "    \n",
        "  # otherwise, the datapoint corresponding to this index is 0(no diabetes)\n",
        "  else:\n",
        "    predictions.append(0) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3GCU5n82UA3J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(predictions)\n",
        "print(y_test['y1'].tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WOxrwk04UQI3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "y_test_y1 = y_test.copy(deep = True)\n",
        "y_test = y_test_y1['y1'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8f-tqBxwv5NZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(type(y_test))\n",
        "for i in range(len(predictions)): \n",
        "  if predictions[i] == y_test[i]: \n",
        "    correct += 1\n",
        "  total +=1\n",
        "accuracy = correct/total\n",
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h4GyBrxyYmBL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Tie it Together"
      ]
    },
    {
      "metadata": {
        "id": "dv-TXHChYsf8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class naive_bayes: \n",
        "  def __init__(self): \n",
        "    self.mean_one = 0 \n",
        "    self.sd_one   = 0\n",
        "    self.mean_zero = 0 \n",
        "    self.sd_zero   = 0 \n",
        "  def fit(self,x,y): \n",
        "    one_y  = y_train[y_train.y1 == 1] \n",
        "    one_x  = x_train.loc[list(one_y.index)]\n",
        "\n",
        "    zero_y = y_train[y_train.y1 == 0]\n",
        "    zero_x = x_train.loc[list(zero_y.index)]\n",
        "    \n",
        "    one_mean  = one_x.mean()\n",
        "    zero_mean = zero_x.mean() \n",
        "    \n",
        "    one_sd    = one_x.std()\n",
        "    zero_sd   = zero_x.std()\n",
        "    \n",
        "    self.mean_one  = one_mean\n",
        "    self.mean_zero = zero_mean\n",
        "    \n",
        "    self.sd_one  = one_sd \n",
        "    self.sd_zero = zero_sd\n",
        "    \n",
        "  def calculateProbability(x, mean, stdev):\n",
        "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
        "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
        "  \n",
        "  def predict(self,x_test):\n",
        "    for i in range(0,len(x_test)):\n",
        "      calc_one = []\n",
        "      for j in range(0,len(self.sd_one)):\n",
        "        calc_one.append(calculateProbability(x_test.iloc[i][j],self.mean_one[j],self.sd_one[j]))\n",
        "      calc_zero = []\n",
        "      for j in range(0,len(self.sd_zero)):\n",
        "        calc_zero.append(calculateProbability(x_test.iloc[i][j],self.mean_zero[j],self.sd_zero[j]))\n",
        "      all_calc.append([calc_one,calc_zero])\n",
        "    predictions = []\n",
        "    for calc in all_calc: \n",
        "      zero = 0\n",
        "      one  = 0\n",
        "      for i in range(0,len(calc[0])): \n",
        "        if calc[0][i] > calc[1][i]: \n",
        "          one += 1\n",
        "        else: \n",
        "          zero += 1\n",
        "      if one > zero: \n",
        "        predictions.append(1)\n",
        "      else:\n",
        "        predictions.append(0) \n",
        "        \n",
        "    return predictions\n",
        "  \n",
        "  def score(self,predict, y_test): \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    y_test_1 = y_test.copy(deep = True)\n",
        "    y_test = y_test_1['y1'].tolist()\n",
        "    for i in range(len(predictions)): \n",
        "      if predictions[i] == y_test[i]: \n",
        "        correct += 1\n",
        "      total +=1\n",
        "    accuracy = correct/total\n",
        "    print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BIlSFPC_zIwR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size = .2,random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H5hEX3CZtP9O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf = naive_bayes()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_sTnfoFAtT1f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf.fit(x_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dpee3xrJtXvX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict = clf.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QDWJQGPOtwNS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf.score(predict,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B2a0tWLM0EMd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Sklearn's Naive Bayes\n"
      ]
    },
    {
      "metadata": {
        "id": "UOVgGxsr0M5b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DpFDw88J0PQE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf = GaussianNB()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QyCfo3QJ0UtJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf.fit(x_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lf_JzPlm0ZAQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict = clf.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pBXgRzoa0b6c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf.score(x_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}